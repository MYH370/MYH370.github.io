<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-spark搭建" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/23/spark%E6%90%AD%E5%BB%BA/" class="article-date">
  <time class="dt-published" datetime="2022-05-23T12:42:04.714Z" itemprop="datePublished">2022-05-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="title-我的第一篇博客"><a href="#title-我的第一篇博客" class="headerlink" title="title: 我的第一篇博客"></a>title: 我的第一篇博客</h2><p>Kafka</p>
<p>分组问题报告</p>
<p>班级：      大数据1901   </p>
<p>学号：      194800132 194800117 194800118  </p>
<p>​            194800123                    </p>
<p>姓名：      陈利明 金文祺 周亚东 马永航             </p>
<p>指导教师：      于智龙       </p>
<table>
<thead>
<tr>
<th>分组问题</th>
<th>1</th>
<th>题目</th>
<th>Kafka全流程配置与应用</th>
</tr>
</thead>
<tbody><tr>
<td>问题目的</td>
<td>熟练操作Kafka相关配置、并对相应配置流程、应用逻辑进行梳理。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>问题内容</td>
<td>请各组同学，按以下要求完成一份《Kafka全流程配置与应用》文档。 要求：文档使用word进行编辑（word模板如下）。配置文档需从Kafka环境配置开始，可借鉴课程中的文档进行编写。编写顺序为：1. Kafka环境配置 -&gt;2. Kafka命令行操作 -&gt;3. 生产者API -&gt;4. 消费者API -&gt;5. Topic管理API</td>
<td></td>
<td></td>
</tr>
<tr>
<td>问题进度</td>
<td>本次共有  5  个练习（具体到每个小练习），完成  5   个</td>
<td></td>
<td></td>
</tr>
<tr>
<td>问题设计</td>
<td>任务分配Kafka环境配置陈利明Kafka命令行操作陈利明生产者API周亚东、陈利明消费者API马永航、陈利明Topic管理API金文祺、陈利明 一、Kafka环境配置1.上传kafka_2.11-2.0.0.tgz到export&#x2F;server，使用tar -zxvf kafka_2.11-2.0.0.tgz命令解压<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps15.jpg" alt="img"> <img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps16.jpg" alt="img"> 2. 对解压后的Kafka创建软连接方便访问ln -s &#x2F;export&#x2F;server&#x2F;kafka_2.11-2.0.0 &#x2F;export&#x2F;server&#x2F;kafka<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps17.jpg" alt="img">  3. 修改 &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config路径下的配置文件 编辑vi server.properties 修改以下内容broker.id&#x3D;0.从0开始,每台不能重复.Listeners &#x3D; plaintext:&#x2F;&#x2F;:9092通信用的是明文传递改成：Listeners &#x3D; plaintext:&#x2F;&#x2F;node1:9092设置数据存储的目录路径log.dirs&#x3D;&#x2F;export&#x2F;server&#x2F;data&#x2F;kafka-logs默认分区数num.partitions &#x3D; 1指定 zk 集群地址zookeeper.connect&#x3D;node1:2181,node2:2181,node3:2181<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps18.jpg" alt="img"> 4. 配置环境变量 &#x2F;etc&#x2F;profile<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps19.jpg" alt="img"> source &#x2F;etc&#x2F;profile重新加载环境变量5. cd &#x2F;export&#x2F;server分别把配置文件和环境变量的配置文件分发到node2;node3结点上具体命令如下（内容过长不便截图）scp -r &#x2F;export&#x2F;server&#x2F;kafka&#x2F; node2:$PWDscp -r &#x2F;export&#x2F;server&#x2F;kafka&#x2F; node3:$PWDscp -r &#x2F;etc&#x2F;profile&#x2F; node2:etc&#x2F;profilescp -r &#x2F;etc&#x2F;profile&#x2F; node2:etc&#x2F;profile6. 修改node2和node3的配置文件&#x2F;export&#x2F;server&#x2F;kafka&#x2F;config&#x2F;server.propertiesbroker.id&#x3D;1listeners &#x3D; plaintext:&#x2F;&#x2F;node2:9092<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps20.jpg" alt="img"> broker.id&#x3D;2listeners &#x3D; plaintext:&#x2F;&#x2F;node3:9092<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps21.jpg" alt="img">  7. 启动Kafka使用脚本一键启动<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps22.jpg" alt="img">  二、Kafka命令行操作1. Kafka 中提供了许多命令行工具(位于$KAFKA HOME&#x2F;bin 目录下)用于管理集群的变更。<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps23.jpg" alt="img"> 2. 查看当前可用topic.&#x2F;kafka-topics.sh –zookeeper node1:2181,node2:2181,node3:2181 –create –replication-factor 2 –partitions 2 –topic test<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps24.jpg" alt="img">  3. 创建topicbin&#x2F;kafka-topics.sh –create –topic tpc_2 –partitions 2 –replication-factor 2 –zookeeper node1:2181该方式下,命令会自动判断所要创建的 topic 的分区数及副本数<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps25.jpg" alt="img"> <img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps26.jpg" alt="img"> 4. 删除topicbin&#x2F;kafka-topics.sh  –delete –topic tpc_3 –zookeeper node1：2181删除 topic,需要一个参数处于启用状态: delete.topic.enable &#x3D; true,否则删不掉<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps27.jpg" alt="img"> <img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps28.jpg" alt="img"> 5.  查看topickafka-topics.sh  –delete –topic tpc_1 –zookeeper node1:2181<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps29.jpg" alt="img"> 6. 增加分区数bin&#x2F;kafka-topics.sh –alter –topic tpc_1 –partitions 3 –zookeeper node1:2181需要注意：Kafka 只支持增加分区,不支持减少分区原因是:减少分区,代价太大(数据的转移,日志段拼接合并) 如果真的需要实现此功能,则完全可以重新创建一个分区数较小的主题,然后将现有主题中的消息按照既定的逻辑复制过去; 7. 动态配置topic参数添加、修改配置参数bin&#x2F;kafka-configs.sh –zookeeper node1:2181 –entity-type topics –entity-name tpc_1 –alter –add-config compression.type&#x3D;gzip<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps30.jpg" alt="img"> 删除配置参数bin&#x2F;kafka-configs.sh –zookeeper node1:2181 –entity-type topics –entity-name tpc_1 –alter –delete-config compression.type<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps31.jpg" alt="img"> 8. Kafka命令行生产者与消费者操作(1)生产者:kafka-console-producerbin&#x2F;kafka-console-producer.sh –broker-list node1:9092, node2:9092, node3:9092 –topic tpc_1<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps32.jpg" alt="img">  (2)消费者:kafka-console-consumer1消费消息bin&#x2F;kafka-console-consumer.sh –bootstrap-server node1:9092, node2:9092, node1:9092 –topic tpc_1 –from-beginning(从头开始)<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps33.jpg" alt="img"> 2指定要消费的分区,和要消费的起始 offset bin&#x2F;kafka-console-consumer.sh–bootstrap-servernode1:9092,node2:9092,node3:9092 –topic tcp_1 –offset 2 –partition 0 9. Kafka命令行配置管理bin&#x2F;kafka-configs.sh zookeeper node1: 2181 –describe –entity-type topics –entity-name tpc_1 <img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps34.jpg" alt="img"> 比如查看 broker 的动态配置可以按如下方式执行:bin&#x2F;kafka-configs.sh zookeeper node1: 2181 –describe –entity-type brokers –entity-name 0 –zookeeper node1:2181<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps35.jpg" alt="img"> 三、生产者APIProduce流程图<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps36.png" alt="img"> 1.一个正常的生产逻辑需要具备以下几个步骤(1)配置生产者客户端参数及创建相应的生产者实例(2)构建待发送的消息(3)发送消息(4)关闭生产者实例创建一个maven工程并导入相关依赖<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps37.jpg" alt="img"> 采用默认分区方式将消息散列的发送到各个分区当中（代码图片） Demo详细解释import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import java.util.Properties; public class MyProducer { public static void main(String[ ] args) throws InterruptedException { Properties props &#x3D; new Properties(); &#x2F;&#x2F;设置 kafka 集群的地址\props.put(“bootstrap.servers”, “node1:9092,node2:9092,node3:9092”);&#x2F;&#x2F;ack 模式,取值有 0,1,-1(all) , all 是最慢但最安全的，0不等响应就继续发（可靠性低），1leader会写到本地日志后，然后给响应，producer拿到响应才继续发（follwer还没同步）props.put(“acks”, “all”); props.put(“retries”, 3); &#x2F;&#x2F;失败重试次数-&gt;失败会自动重试（可恢复&#x2F;不可恢复）–&gt;(有可能会造成数据的乱序)props.put(“batch.size”, 10); &#x2F;&#x2F;数据发送的批次大小à提高效率&#x2F;吞吐量à太大会数据延迟props.put(“linger.ms”, 10000); &#x2F;&#x2F;消息在缓冲区保留的时间,超过设置的值就会被提交到服务端props.put(“max.request.size”,10); &#x2F;&#x2F;数据发送请求的最大缓存数props.put(“buffer.memory”, 10240); &#x2F;&#x2F;整个 Producer 用到总内存的大小,如果缓冲区满了会提交数据到服务端&#x2F;&#x2F;buffer.memory 要大于 batch.size,否则会报申请内存不足的错误à降低阻塞的可能性在创建真正的生产者实例前需要配置相应的参数,比如需要连接的 Kafka 集群地址。在 Kafka 生产者客户端 KatkaProducer 中有 3 个参数是必填的。bootstrap.servers key.serializer value.serializer为了防止参数名字符串书写错误,可以使用如下方式进行设置: props.setProperty(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,ProducerInterceptorPrefix.class.getName());props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,”node1:9092,node2:9092”); props.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName()); （运行结果图片2）2. 生产者api参数发送方式（发后即忘）发后即忘,它只管往 Kafka 发送,并不关心消息是否正确到达。在大多数情况下,这种发送方式没有问题; 不过在某些时候(比如发生不可重试异常时)会造成消息的丢失。这种发送方式的性能最高,可靠性最差。Future<RecordMetadata> send &#x3D; producer.send(rcd);3. 同步发送(sync ) try {	producer.send(rcd).get(); } catch (Exception e) { 	e.printStackTrace(); }(新版中,producer 在底层只有异步)4. 异步发送(async )回调函数会在 producer 收到 ack 时调用,为异步调用,该方法有两个参数,分别是 RecordMetadata 和Exception,如果 Exception 为 null,说明消息发送成功,如果 Exception 不为 null,说明消息发送失败。注意:消息发送失败会自动重试,不需要我们在回调函数中手动重试。<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps38.jpg" alt="img"> 四、消费者API1. 一个正常的消费逻辑需要具备以下几个步骤: (1)配置消费者客户端参数(2)创建相应的消费者实例; (3)订阅主题; (4)拉取消息并消费; (5)提交消费位移 offset;(6)关闭消费者实例（代码图片）<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps39.jpg" alt="img"><img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps40.jpg" alt="img"> <img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps41.jpg" alt="img"> 五、Topic管理API一般情况下,我们都习惯使用 kafka-topic.sh 本来管理主题,如果希望将管理类的功能集成到公司内部的系统中,打造集管理、监控、运维、告警为一体的生态平台,那么就需要以程序调用 API 方式去实现。这种调用 API 方式实现管理主要利用 KafkaAdminClient 工具类KafkaAdminClient 不仅可以用来管理 broker、配置和 ACL (Access Control List),还可用来管理主题)它提供了以下方法:1.列出主题ListTopicsResult listTopicsResult &#x3D; adminClient.listTopics(); Set<String> topics &#x3D; listTopicsResult.names().get(); System.out.println(topics);2.查看主题信息DescribeTopicsResultdescribeTopicsResult&#x3D; &#x3D; adminClient.describeTopics(Arrays.asList(“tpc_3”, “tpc_4”)); Map&lt;String, TopicDescription&gt; res &#x3D; describeTopicsResult.all().get();Set<String> ksets &#x3D; res.keySet(); for (String k : ksets) { 	System.out.println(res.get(k)); }3.创建主题代码示例:&#x2F;&#x2F; 参数配置Properties props &#x3D; new Properties(); props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,”node1:9092,node2:9092,node3:9092”); props.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG,3000); &#x2F;&#x2F; 创建 admin client 对象AdminClient adminClient &#x3D; KafkaAdminClient.create(props); &#x2F;&#x2F; 由服务端 controller 自行分配分区及副本所在 broker NewTopic tpc_3 &#x3D; new NewTopic(“tpc_3”, 2, (short) 1); &#x2F;&#x2F; 手动指定分区及副本的 broker 分配HashMap&lt;Integer, List<Integer>&gt; replicaAssignments &#x3D; new HashMap&lt;&gt;(); &#x2F;&#x2F;分区0分配到broker0,broker1 replicaAssignments.put(0,Arrays.asList(0,1)); &#x2F;&#x2F; 分区 1,分配到 broker0,broker2 replicaAssignments.put(0,Arrays.asList(0,1));NewTopic tpc_4 &#x3D; new NewTopic(“tpc_4”, replicaAssignments); CreateTopicsResultresult&#x3D; &#x3D; adminClient.createTopics(Arrays.asList(tpc_3,tpc_4)); &#x2F;&#x2F; 从 future 中等待服务端返回try { 	result.all().get(); } catch (Exception e) { e.printStackTrace(); } adminClient.close();4.删除主题代码示例: DeleteTopicsResultdeleteTopicsResult&#x3D; &#x3D; adminClient.deleteTopics(Arrays.asList(“tpc_1”, “tpc_1”)); Map&lt;String, KafkaFuture<Void>&gt; values &#x3D; deleteTopicsResult.values(); System.out.println(values);5.除了进行 topic 管理之外,KafkaAdminClient 也可以进行诸如动态参数管理,分区管理等各类管理操作;<img src="file:///C:\Users\雷神\AppData\Local\Temp\ksohtml8104\wps42.jpg" alt="img"></td>
<td></td>
<td></td>
</tr>
<tr>
<td>问题总结</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>成绩</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/23/spark%E6%90%AD%E5%BB%BA/" data-id="cl3iq0ulf0000y8w29w7a5yes" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2022/05/17/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


</section>
        <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/05/23/spark%E6%90%AD%E5%BB%BA/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/05/17/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li></ul>
    </div>
  </div>

  
</aside>
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 By Autoload<br>
      Driven - <a href="https://hexo.io/" target="_blank">Hexo</a>|Theme - <a href="https://github.com/autoload/hexo-theme-auto" target="_blank">Auto</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>